"""
ASR –º–æ–¥—É–ª—å —Å T-one –æ—Ç –¢-–ë–∞–Ω–∫–∞ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã warnings).
"""

import torch
import numpy as np
from typing import Dict, Any
import logging
import io
import warnings

# –ü–æ–¥–∞–≤–ª—è–µ–º warning –æ torch_dtype
warnings.filterwarnings("ignore", message=".*torch_dtype.*")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ToneASR:
    """
    T-one ASR –æ—Ç –¢-–ë–∞–Ω–∫–∞ (70M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤).
    HuggingFace: https://huggingface.co/t-tech/T-one
    """

    def __init__(self, device: str = "auto", max_memory_usage: float = 0.9):
        """
        Args:
            device: "cpu", "cuda" –∏–ª–∏ "auto"
            max_memory_usage: –ü—Ä–æ—Ü–µ–Ω—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –ø–∞–º—è—Ç–∏ (0.9 = 90%)
        """
        if device == "auto":
            device = "cuda" if torch.cuda.is_available() else "cpu"

        self.device = device
        self.max_memory_usage = max_memory_usage
        self.model = None
        self.processor = None

        self._init_model()

    def _init_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç T-one —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
        try:
            from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor
            import warnings

            logger.info("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º T-one (70M –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)...")

            model_name = "t-tech/T-one"

            # –ó–∞–≥—Ä—É–∂–∞–µ–º processor
            self.processor = Wav2Vec2Processor.from_pretrained(model_name)

            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏
            model_kwargs = {
                "low_cpu_mem_usage": True,
            }

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è GPU
            if self.device == "cuda":
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º dtype –≤–º–µ—Å—Ç–æ torch_dtype
                model_kwargs["torch_dtype"] = torch.float16

                # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞–º—è—Ç–∏ –¥–ª—è accelerate
                max_memory = {0: f"{int(self.max_memory_usage * 100)}%"}
                model_kwargs["device_map"] = "auto"
                model_kwargs["max_memory"] = max_memory

            # –ü–æ–¥–∞–≤–ª—è–µ–º deprecation warning
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore", category=FutureWarning)
                warnings.filterwarnings("ignore", message=".*torch_dtype.*")

                self.model = Wav2Vec2ForCTC.from_pretrained(
                    model_name,
                    **model_kwargs
                )

            # –î–ª—è CPU –ø–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –≤—Ä—É—á–Ω—É—é
            if self.device == "cpu":
                self.model = self.model.to("cpu")

            self.model.eval()

            logger.info(f"‚úÖ T-one –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.device}")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–ª—è GPU
            if self.device == "cuda":
                allocated = torch.cuda.memory_allocated(0) / 1024**3
                logger.info(f"üìä –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ GPU –ø–∞–º—è—Ç–∏: {allocated:.2f} GB")

        except ImportError as e:
            raise ImportError(
                "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:\n"
                "pip install transformers torch torchaudio soundfile librosa accelerate"
            ) from e
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            raise

    def transcribe_bytes(
        self,
        audio_data: bytes,
        sample_rate: int = 16000
    ) -> Dict[str, Any]:
        """
        –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å –∏–∑ –±–∞–π—Ç–æ–≤.

        Args:
            audio_data: –ê—É–¥–∏–æ –≤ –±–∞–π—Ç–∞—Ö (WAV —Ñ–æ—Ä–º–∞—Ç)
            sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏

        Returns:
            {"text": "—Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç", "success": True}
        """
        try:
            import soundfile as sf

            # –ß–∏—Ç–∞–µ–º WAV –∏–∑ –±–∞–π—Ç–æ–≤
            audio_io = io.BytesIO(audio_data)
            waveform, sr = sf.read(audio_io)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy array
            if isinstance(waveform, np.ndarray):
                if waveform.ndim > 1:
                    waveform = waveform[:, 0]  # –ú–æ–Ω–æ

            # –†–µ—Å—ç–º–ø–ª–∏—Ä—É–µ–º –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if sr != 16000:
                try:
                    import librosa
                    waveform = librosa.resample(waveform, orig_sr=sr, target_sr=16000)
                except ImportError:
                    # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º torchaudio
                    import torchaudio
                    waveform_tensor = torch.FloatTensor(waveform).unsqueeze(0)
                    resampler = torchaudio.transforms.Resample(sr, 16000)
                    waveform = resampler(waveform_tensor).squeeze().numpy()

            # –†–∞—Å–ø–æ–∑–Ω–∞—ë–º
            inputs = self.processor(
                waveform,
                sampling_rate=16000,
                return_tensors="pt",
                padding=True
            )

            # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ device
            if self.device == "cuda":
                inputs = {k: v.to("cuda") for k, v in inputs.items()}

            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å
            with torch.no_grad():
                logits = self.model(**inputs).logits

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º
            predicted_ids = torch.argmax(logits, dim=-1)
            transcription = self.processor.batch_decode(predicted_ids)[0]

            text = transcription.strip()

            logger.info(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {text}")

            return {
                "text": text,
                "success": True,
                "engine": "t-one",
                "language": "ru"
            }

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {e}")
            return {
                "text": "",
                "success": False,
                "error": str(e),
                "engine": "t-one"
            }

    def get_info(self) -> Dict[str, str]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏."""
        info = {
            "engine": "T-one (–¢-–ë–∞–Ω–∫)",
            "status": "‚úÖ –ì–æ—Ç–æ–≤" if self.model else "‚ùå –ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω",
            "parameters": "70M",
            "device": self.device,
            "github": "https://github.com/voicekit-team/T-one"
        }

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞–º—è—Ç–∏ –¥–ª—è GPU
        if self.device == "cuda" and torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(0) / 1024**3
            total = torch.cuda.get_device_properties(0).total_memory / 1024**3
            info["gpu_memory"] = f"{allocated:.2f}GB / {total:.2f}GB"

        return info
