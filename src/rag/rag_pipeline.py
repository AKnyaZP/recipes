from typing import List, Dict, Any, Optional
import time
from pathlib import Path
import os
from loguru import logger
import asyncio
import concurrent.futures

from data.data_loader import (
    load_povarenok_data,
    prepare_documents,
    save_processed_data,
    load_processed_data,
)
from embeddings.embeddings import RecipeEmbedder
from store.vector_store import FAISSVectorStore
from rag.hybrid_search import HybridSearch
from llm.llm import RecipeLLM
from rag.reranker import RecipeReranker  # –ù–æ–≤—ã–π –∏–º–ø–æ—Ä—Ç




def _to_list_of_dicts(obj) -> Optional[List[Dict[str, Any]]]:
    """
    –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–∏–≤–µ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç –∫ —Å–ø–∏—Å–∫—É —Å–ª–æ–≤–∞—Ä–µ–π.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: list[dict], dict (–∫–ª—é—á -> list), HF Dataset/DatasetDict, pandas DataFrame –∏ —Ç.–¥.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏.
    """
    if obj is None:
        return None

    if isinstance(obj, list):
        return obj

    if isinstance(obj, dict):
        for k, v in obj.items():
            if isinstance(v, list) and v and isinstance(v[0], dict):
                return v
        list_values = [v for v in obj.values() if isinstance(v, list)]
        if list_values:
            length = len(list_values[0])
            try:
                keys = list(obj.keys())
                records = []
                for i in range(length):
                    rec = {}
                    for k in keys:
                        val = obj[k]
                        rec[k] = val[i] if isinstance(val, list) and i < len(val) else None
                    records.append(rec)
                return records
            except Exception:
                pass
        return None

    try:
        if hasattr(obj, "to_dict"):
            d = obj.to_dict()
            if isinstance(d, dict):
                for v in d.values():
                    if isinstance(v, list) and v and isinstance(v[0], dict):
                        return v
                list_values = [v for v in d.values() if isinstance(v, list)]
                if list_values:
                    length = len(list_values[0])
                    keys = list(d.keys())
                    records = []
                    for i in range(length):
                        rec = {}
                        for k in keys:
                            val = d[k]
                            rec[k] = val[i] if isinstance(val, list) and i < len(val) else None
                        records.append(rec)
                    return records

        if hasattr(obj, "to_records") or hasattr(obj, "to_dict"):
            try:
                recs = obj.to_dict(orient="records")
                if isinstance(recs, list):
                    return recs
            except Exception:
                pass

        try:
            lst = list(obj)
            if lst and isinstance(lst[0], dict):
                return lst
        except Exception:
            pass
    except Exception:
        pass

    return None


class RecipeRAGPipeline:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤.
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö, –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é, –ø–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    –í–∫–ª—é—á–∞–µ—Ç —Ä–µ—Ä–∞–Ω–∫–µ—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """

    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç RAG –ø–∞–π–ø–ª–∞–π–Ω.
        """
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ä–µ—Ü–µ–ø—Ç–æ–≤")

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
        self.embedder: Optional[RecipeEmbedder] = None
        self.vector_store: Optional[FAISSVectorStore] = None
        self.hybrid_search: Optional[HybridSearch] = None
        self.llm: Optional[RecipeLLM] = None
        self.reranker: Optional[RecipeReranker] = None  # –ù–æ–≤—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        self.documents: List[Dict[str, Any]] = []

        logger.info("‚úÖ RAG –ø–∞–π–ø–ª–∞–π–Ω —Å–æ–∑–¥–∞–Ω")

    def setup_embeddings(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        """
        logger.info("\n–®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
        self.embedder = RecipeEmbedder()

    def _load_and_process_data_sync(self, max_recipes: int = None):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        """
        logger.info(f"\n –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ª–∏–º–∏—Ç: {max_recipes or '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'})")

        # compute processed file path at repo root /data/processed_recipes.json
        processed_file = Path(__file__).resolve().parents[2] / "data" / "processed_recipes.json"

        # 1) –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π processed —Ñ–∞–π–ª (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
        processed = None
        if processed_file.exists():
            try:
                logger.info(f" –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {processed_file}")
                processed = load_processed_data(str(processed_file))
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ processed_file: {e}")
                processed = None

        if not processed:
            logger.info("‚Ñπprocessed data –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç/–ø—É—Å—Ç—ã ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            hf_token = os.getenv("HF_TOKEN")

            raw_recipes = None
            try:
                raw_recipes = load_povarenok_data(max_recipes=max_recipes, use_auth_token=hf_token)
            except TypeError:
                try:
                    raw_recipes = load_povarenok_data("rogozinushka/povarenok-recipes", max_recipes=max_recipes, use_auth_token=hf_token)
                except TypeError:
                    try:
                        raw_recipes = load_povarenok_data()
                    except Exception as e:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–∑–≤–∞—Ç—å load_povarenok_data –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {e}")
                        raw_recipes = None
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö (second attempt): {e}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö (first attempt): {e}")

            if not raw_recipes:
                raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ—Ü–µ–ø—Ç—ã (raw_recipes –ø—É—Å—Ç—ã–µ). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ HF_TOKEN.")

            logger.info("–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
            try:
                try:
                    processed = prepare_documents(raw_recipes, max_recipes)
                except TypeError:
                    processed = prepare_documents(raw_recipes)
            except Exception as e:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ prepare_documents: {e}")

            if not processed:
                raise RuntimeError("prepare_documents –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

            try:
                try:
                    save_processed_data(processed, str(processed_file))
                except TypeError:
                    save_processed_data(str(processed_file), processed)
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {processed_file}")
            except Exception as e:
                logger.warning(f" –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å processed data –Ω–∞ –¥–∏—Å–∫: {e}")

        normalized = _to_list_of_dicts(processed)
        if normalized is None:
            if not processed_file.exists():
                raise RuntimeError("Processed data –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∏ –∫—ç—à –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")
            else:
                try:
                    reloaded = load_processed_data(str(processed_file))
                    normalized = _to_list_of_dicts(reloaded)
                except Exception:
                    normalized = None

            if normalized is None:
                raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏ processed data –∫ —Å–ø–∏—Å–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –¢–∏–ø –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞: {type(processed)}")

        if max_recipes and len(normalized) > max_recipes:
            normalized = normalized[:max_recipes]
            logger.info(f" –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {max_recipes} —Ä–µ—Ü–µ–ø—Ç–æ–≤")

        self.documents = normalized
        logger.info(f"–ì–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ —Å {len(self.documents)} —Ä–µ—Ü–µ–ø—Ç–∞–º–∏")

    def load_and_process_data(self, max_recipes: int = None):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ä–µ—Ü–µ–ø—Ç–æ–≤.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.

        Args:
            max_recipes: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            loop = asyncio.get_running_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._load_and_process_data_sync, max_recipes)
                return future.result()
        except RuntimeError:
            return self._load_and_process_data_sync(max_recipes)

    def _build_vector_index_sync(self, force_rebuild: bool = False):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞.
        """
        logger.info("\n –®–∞–≥ 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")

        if not self.embedder:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Å –ø–æ–º–æ—â—å—é setup_embeddings()")

        if not self.documents or len(self.documents) == 0:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é load_and_process_data(); –Ω–∞–π–¥–µ–Ω–æ 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        self.vector_store = FAISSVectorStore(self.embedder.embedding_dim)

        index_path = Path(__file__).resolve().parents[2] / "data" / "faiss_index"

        if index_path.exists() and not force_rebuild:
            logger.info("–ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
            try:
                self.vector_store.load(str(index_path))
                return
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
                logger.info(" –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å...")

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        logger.info("–í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
        texts = [doc.get("full_text", "") for doc in self.documents]
        embeddings = self.embedder.encode_texts(texts)

        logger.info(" –°—Ç—Ä–æ–∏–º FAISS –∏–Ω–¥–µ–∫—Å...")
        self.vector_store.build_index(embeddings, self.documents)

        logger.info("–°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å...")
        self.vector_store.save(str(index_path))

        logger.info("–í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≥–æ—Ç–æ–≤")

    def build_vector_index(self, force_rebuild: bool = False):
        """
        –°—Ç—Ä–æ–∏—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å FAISS.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.

        Args:
            force_rebuild: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        """
        try:
            loop = asyncio.get_running_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._build_vector_index_sync, force_rebuild)
                return future.result()
        except RuntimeError:
            return self._build_vector_index_sync(force_rebuild)

    def setup_hybrid_search(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫.
        """
        logger.info("\n –®–∞–≥ 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")

        if not self.vector_store or not self.documents:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å")

        self.hybrid_search = HybridSearch(self.vector_store, self.documents)
        logger.info("–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –≥–æ—Ç–æ–≤")

    def setup_reranker(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Ä–µ—Ä–∞–Ω–∫–µ—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞.
        """
        logger.info("\n –®–∞–≥ 4.5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ—Ä–∞–Ω–∫–µ—Ä–∞")

        try:
            self.reranker = RecipeReranker("cross-encoder/ms-marco-MiniLM-L-6-v2")
            logger.info("–†–µ—Ä–∞–Ω–∫–µ—Ä –≥–æ—Ç–æ–≤")
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ—Ä–∞–Ω–∫–µ—Ä: {e}. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Ä–µ—Ä–∞–Ω–∫–µ—Ä–∞.")
            self.reranker = None

    def setup_llm(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å.
        """
        logger.info("\n–®–∞–≥ 5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏")

        self.llm = RecipeLLM("Qwen/Qwen2.5-1.5B-Instruct")

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = self.llm.get_model_info()
        logger.info(f"–ú–æ–¥–µ–ª—å: {model_info.get('model_name', 'unknown')}")
        logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: ~{model_info.get('num_parameters', 0):,}")
        logger.info("LLM –≥–æ—Ç–æ–≤–∞")

    def _initialize_full_pipeline_sync(self, max_recipes: int = None, force_rebuild: bool = False):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–ª–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
        """
        logger.info("–ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞")

        start_time = time.time()

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.setup_embeddings()
        self.load_and_process_data(max_recipes)
        self.build_vector_index(force_rebuild)
        self.setup_hybrid_search()
        self.setup_reranker()  
        self.setup_llm()

        elapsed = time.time() - start_time
        logger.info(f"\n–ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.1f}—Å")
        logger.info("RAG –ø–∞–π–ø–ª–∞–π–Ω –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")

    def initialize_full_pipeline(self, max_recipes: int = None, force_rebuild: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω –∑–∞ –æ–¥–∏–Ω –≤—ã–∑–æ–≤.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.

        Args:
            max_recipes: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤
            force_rebuild: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        """
        try:
            loop = asyncio.get_running_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._initialize_full_pipeline_sync, max_recipes, force_rebuild)
                return future.result()
        except RuntimeError:
            return self._initialize_full_pipeline_sync(max_recipes, force_rebuild)

    def _search_recipes_sync(self, query: str, k: int = 5) -> List[tuple]:
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤ —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º.
        """
        if not self.hybrid_search or not self.embedder:
            raise ValueError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        query_embedding = self.embedder.encode_query(query)

        initial_k = min(k * 3, 20)  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
        raw_results = self.hybrid_search.hybrid_search(
            query=query,
            query_embedding=query_embedding,
            k=initial_k,
            alpha=0.6,
        )

        if self.reranker and raw_results:
            docs = [doc for doc, _ in raw_results]

            filter_result = self.reranker.filter_by_intent(query, docs)
            filtered_docs = filter_result['filtered_docs']
            intent_info = filter_result['intent_info']

            logger.info(f" –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ: {intent_info['intent']} (confidence: {intent_info['confidence']:.2f})")

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥
            if filtered_docs:
                reranked_docs = self.reranker.rerank(query, filtered_docs, top_k=k)
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ (doc, score)
                return [(doc, i) for i, doc in enumerate(reranked_docs)]
            else:
                logger.warning(" –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—é –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return raw_results[:k]

    def search_recipes(self, query: str, k: int = 5) -> List[tuple]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Ä–µ—Ü–µ–ø—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        """
        try:
            loop = asyncio.get_running_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._search_recipes_sync, query, k)
                return future.result()
        except RuntimeError:
            return self._search_recipes_sync(query, k)

    def _ask_sync(self, question: str) -> Dict[str, Any]:
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        """
        if not all([self.hybrid_search, self.embedder, self.llm]):
            raise ValueError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        logger.info(f"\n–í–æ–ø—Ä–æ—Å: {question}")

        start_time = time.time()

        search_results = self._search_recipes_sync(question, k=5)

        search_time = time.time() - start_time

        response = self.llm.generate_response(question, search_results)

        total_time = time.time() - start_time

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "question": question,
            "answer": response,
            "found_recipes": len(search_results) if search_results is not None else 0,
            "search_results": [
                {
                    "name": doc.get("name", ""),
                    "ingredients": doc.get("ingredients_text", ""),
                    "url": doc.get("url", ""),
                    "relevance_score": float(score) if isinstance(score, (int, float)) else 0.0,
                }
                for doc, score in (search_results or [])[:3]
            ],
            "timing": {"search_time": round(search_time, 3), "total_time": round(total_time, 3)},
        }

        logger.info(f" –û—Ç–≤–µ—Ç: {response}")
        logger.info(f"–í—Ä–µ–º—è: {total_time:.3f}—Å (–ø–æ–∏—Å–∫: {search_time:.3f}—Å)")

        return result

    def ask(self, question: str) -> Dict[str, Any]:
        """
        –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ —Ä–µ—Ü–µ–ø—Ç–∞—Ö.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        """
        try:
            loop = asyncio.get_running_loop()
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._ask_sync, question)
                return future.result()
        except RuntimeError:
            return self._ask_sync(question)
