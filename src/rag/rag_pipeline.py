from typing import List, Dict, Any, Optional
import time
from pathlib import Path
import os
from logging import getLogger
import asyncio
import concurrent.futures

from data.data_loader import (
    load_povarenok_data,
    prepare_documents,
    save_processed_data,
    load_processed_data,
)
from embeddings.embeddings import RecipeEmbedder
from store.vector_store import FAISSVectorStore
from rag.hybrid_search import HybridSearch
from llm.llm import RecipeLLM
from rag.reranker import RecipeReranker  # –ù–æ–≤—ã–π –∏–º–ø–æ—Ä—Ç

logger = getLogger(__name__)
logger.setLevel("DEBUG")


def _to_list_of_dicts(obj) -> Optional[List[Dict[str, Any]]]:
    """
    –ü–æ–ø—ã—Ç–∫–∞ –ø—Ä–∏–≤–µ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç –∫ —Å–ø–∏—Å–∫—É —Å–ª–æ–≤–∞—Ä–µ–π.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: list[dict], dict (–∫–ª—é—á -> list), HF Dataset/DatasetDict, pandas DataFrame –∏ —Ç.–¥.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏.
    """
    if obj is None:
        return None

    # already list of dicts?
    if isinstance(obj, list):
        return obj

    # dict of lists -> convert by zipping
    if isinstance(obj, dict):
        # –µ—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞ {'train': [...]}
        # –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø–µ—Ä–≤—É—é –ø–æ–¥—Ö–æ–¥—è—â—É—é –∑–∞–ø–∏—Å—å —Å–æ —Å–ø–∏—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–ª–æ–≤–∞—Ä–µ–π
        # –∏–ª–∏ –∫–ª—é—á —Å–æ —Å–ø–∏—Å–∫–æ–º –¥–ª–∏–Ω–Ω–æ–π > 0
        for k, v in obj.items():
            if isinstance(v, list) and v and isinstance(v[0], dict):
                return v
        # –µ—Å–ª–∏ dict of lists (columns) -> zip to records
        list_values = [v for v in obj.values() if isinstance(v, list)]
        if list_values:
            length = len(list_values[0])
            try:
                keys = list(obj.keys())
                records = []
                for i in range(length):
                    rec = {}
                    for k in keys:
                        val = obj[k]
                        rec[k] = val[i] if isinstance(val, list) and i < len(val) else None
                    records.append(rec)
                return records
            except Exception:
                pass
        return None

    # objects with to_pandas / to_dict / to_list behaviour (HF Dataset, pandas.DataFrame)
    try:
        # HF Dataset / DatasetDict -> try iterate or use to_dict
        if hasattr(obj, "to_dict"):
            d = obj.to_dict()
            # if to_dict returns dict of lists -> convert
            if isinstance(d, dict):
                # DatasetDict returns {split: Dataset}, handle that
                # if values are lists -> zip to records
                for v in d.values():
                    if isinstance(v, list) and v and isinstance(v[0], dict):
                        return v
                # if d itself is columns -> zip
                list_values = [v for v in d.values() if isinstance(v, list)]
                if list_values:
                    length = len(list_values[0])
                    keys = list(d.keys())
                    records = []
                    for i in range(length):
                        rec = {}
                        for k in keys:
                            val = d[k]
                            rec[k] = val[i] if isinstance(val, list) and i < len(val) else None
                        records.append(rec)
                    return records

        # try pandas
        if hasattr(obj, "to_records") or hasattr(obj, "to_dict"):
            try:
                # pandas.DataFrame -> to_dict(orient='records')
                recs = obj.to_dict(orient="records")
                if isinstance(recs, list):
                    return recs
            except Exception:
                pass

        # fallback: try to iterate and coerce to list
        try:
            lst = list(obj)
            # ensure elements are dicts
            if lst and isinstance(lst[0], dict):
                return lst
            # if elements are tuples/lists and correspond to columns, try to convert
        except Exception:
            pass
    except Exception:
        pass

    return None


class RecipeRAGPipeline:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å RAG –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤.
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö, –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é, –ø–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
    –í–∫–ª—é—á–∞–µ—Ç —Ä–µ—Ä–∞–Ω–∫–µ—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    """

    def __init__(self):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç RAG –ø–∞–π–ø–ª–∞–π–Ω.
        """
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º RAG –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ä–µ—Ü–µ–ø—Ç–æ–≤")

        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–∞–π–ø–ª–∞–π–Ω–∞
        self.embedder: Optional[RecipeEmbedder] = None
        self.vector_store: Optional[FAISSVectorStore] = None
        self.hybrid_search: Optional[HybridSearch] = None
        self.llm: Optional[RecipeLLM] = None
        self.reranker: Optional[RecipeReranker] = None  # –ù–æ–≤—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        self.documents: List[Dict[str, Any]] = []

        logger.info("‚úÖ RAG –ø–∞–π–ø–ª–∞–π–Ω —Å–æ–∑–¥–∞–Ω")

    def setup_embeddings(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        """
        logger.info("\nüìù –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏")
        self.embedder = RecipeEmbedder()

    def _load_and_process_data_sync(self, max_recipes: int = None):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö.
        """
        logger.info(f"\nüìÇ –®–∞–≥ 2: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–ª–∏–º–∏—Ç: {max_recipes or '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'})")

        # compute processed file path at repo root /data/processed_recipes.json
        processed_file = Path(__file__).resolve().parents[2] / "data" / "processed_recipes.json"

        # 1) –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –≥–æ—Ç–æ–≤—ã–π processed —Ñ–∞–π–ª (–µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
        processed = None
        if processed_file.exists():
            try:
                logger.info(f"üìã –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {processed_file}")
                processed = load_processed_data(str(processed_file))
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ processed_file: {e}")
                processed = None

        # 2) –ï—Å–ª–∏ processed –ø—É—Å—Ç –∏–ª–∏ None -> –∑–∞–≥—Ä—É–∑–∏–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–µ–º
        if not processed:
            logger.info("‚ÑπÔ∏è processed data –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç/–ø—É—Å—Ç—ã ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ...")
            hf_token = os.getenv("HF_TOKEN")

            # –í—ã–∑–æ–≤ load_povarenok_data: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–∏–≥–Ω–∞—Ç—É—Ä
            raw_recipes = None
            try:
                # try signature with max_recipes kwarg
                raw_recipes = load_povarenok_data(max_recipes=max_recipes, use_auth_token=hf_token)
            except TypeError:
                try:
                    # common alternative: load_povarenok_data(dataset_id, max_recipes=...)
                    raw_recipes = load_povarenok_data("rogozinushka/povarenok-recipes", max_recipes=max_recipes, use_auth_token=hf_token)
                except TypeError:
                    try:
                        # try simple call without args
                        raw_recipes = load_povarenok_data()
                    except Exception as e:
                        logger.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–∑–≤–∞—Ç—å load_povarenok_data –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {e}")
                        raw_recipes = None
                except Exception as e:
                    logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö (second attempt): {e}")
            except Exception as e:
                logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö (first attempt): {e}")

            if not raw_recipes:
                raise RuntimeError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ—Ü–µ–ø—Ç—ã (raw_recipes –ø—É—Å—Ç—ã–µ). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–ª–∏ HF_TOKEN.")

            logger.info("‚öôÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
            try:
                # prepare_documents –º–æ–∂–µ—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä max_recipes
                try:
                    processed = prepare_documents(raw_recipes, max_recipes)
                except TypeError:
                    processed = prepare_documents(raw_recipes)
            except Exception as e:
                raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ prepare_documents: {e}")

            if not processed:
                raise RuntimeError("prepare_documents –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            try:
                # try signature save_processed_data(processed, path) or save_processed_data(path, processed)
                try:
                    save_processed_data(processed, str(processed_file))
                except TypeError:
                    save_processed_data(str(processed_file), processed)
                logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {processed_file}")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å processed data –Ω–∞ –¥–∏—Å–∫: {e}")

        # 3) –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º processed –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
        normalized = _to_list_of_dicts(processed)
        if normalized is None:
            # –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—Å—ë –µ—â—ë –Ω–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ø—Ä–æ–±—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ load_processed_data –µ—Å–ª–∏ –Ω–µ –¥–µ–ª–∞–ª–∏ —Ä–∞–Ω–µ–µ
            if not processed_file.exists():
                raise RuntimeError("Processed data –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π –∏ –∫—ç—à –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.")
            else:
                # –ø–æ–ø—ã—Ç–∫–∞ –µ—â—ë —Ä–∞–∑ –∑–∞–≥—Ä—É–∑–∏—Ç—å —á–µ—Ä–µ–∑ load_processed_data
                try:
                    reloaded = load_processed_data(str(processed_file))
                    normalized = _to_list_of_dicts(reloaded)
                except Exception:
                    normalized = None

            if normalized is None:
                raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏ processed data –∫ —Å–ø–∏—Å–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –¢–∏–ø –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞: {type(processed)}")

        # –ø—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if max_recipes and len(normalized) > max_recipes:
            normalized = normalized[:max_recipes]
            logger.info(f"üî¨ –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ {max_recipes} —Ä–µ—Ü–µ–ø—Ç–æ–≤")

        self.documents = normalized
        logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ –∫ —Ä–∞–±–æ—Ç–µ —Å {len(self.documents)} —Ä–µ—Ü–µ–ø—Ç–∞–º–∏")

    def load_and_process_data(self, max_recipes: int = None):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ä–µ—Ü–µ–ø—Ç–æ–≤.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.

        Args:
            max_recipes: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ running event loop
            loop = asyncio.get_running_loop()
            # –ï—Å–ª–∏ –µ—Å—Ç—å loop, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ executor
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._load_and_process_data_sync, max_recipes)
                return future.result()
        except RuntimeError:
            # –ù–µ—Ç event loop - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return self._load_and_process_data_sync(max_recipes)

    def _build_vector_index_sync(self, force_rebuild: bool = False):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞.
        """
        logger.info("\nüóÑÔ∏è –®–∞–≥ 3: –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")

        if not self.embedder:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é —Å –ø–æ–º–æ—â—å—é setup_embeddings()")

        if not self.documents or len(self.documents) == 0:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é load_and_process_data(); –Ω–∞–π–¥–µ–Ω–æ 0 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        self.vector_store = FAISSVectorStore(self.embedder.embedding_dim)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å
        index_path = Path(__file__).resolve().parents[2] / "data" / "faiss_index"

        if index_path.exists() and not force_rebuild:
            logger.info("üìÇ –ù–∞–π–¥–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∏–Ω–¥–µ–∫—Å, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
            try:
                self.vector_store.load(str(index_path))
                return
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–∞: {e}")
                logger.info("üî® –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å...")

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
        logger.info("üîÑ –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã...")
        texts = [doc.get("full_text", "") for doc in self.documents]
        embeddings = self.embedder.encode_texts(texts)

        logger.info("üèóÔ∏è –°—Ç—Ä–æ–∏–º FAISS –∏–Ω–¥–µ–∫—Å...")
        self.vector_store.build_index(embeddings, self.documents)

        logger.info("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å...")
        self.vector_store.save(str(index_path))

        logger.info("‚úÖ –í–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≥–æ—Ç–æ–≤")

    def build_vector_index(self, force_rebuild: bool = False):
        """
        –°—Ç—Ä–æ–∏—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å FAISS.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.

        Args:
            force_rebuild: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ running event loop
            loop = asyncio.get_running_loop()
            # –ï—Å–ª–∏ –µ—Å—Ç—å loop, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ executor
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._build_vector_index_sync, force_rebuild)
                return future.result()
        except RuntimeError:
            # –ù–µ—Ç event loop - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return self._build_vector_index_sync(force_rebuild)

    def setup_hybrid_search(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫.
        """
        logger.info("\nüîç –®–∞–≥ 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")

        if not self.vector_store or not self.documents:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ –ø–æ—Å—Ç—Ä–æ–π—Ç–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å")

        self.hybrid_search = HybridSearch(self.vector_store, self.documents)
        logger.info("‚úÖ –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ –≥–æ—Ç–æ–≤")

    def setup_reranker(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —Ä–µ—Ä–∞–Ω–∫–µ—Ä –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞.
        """
        logger.info("\nüéØ –®–∞–≥ 4.5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–µ—Ä–∞–Ω–∫–µ—Ä–∞")

        try:
            self.reranker = RecipeReranker("cross-encoder/ms-marco-MiniLM-L-6-v2")
            logger.info("‚úÖ –†–µ—Ä–∞–Ω–∫–µ—Ä –≥–æ—Ç–æ–≤")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ä–µ—Ä–∞–Ω–∫–µ—Ä: {e}. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —Ä–µ—Ä–∞–Ω–∫–µ—Ä–∞.")
            self.reranker = None

    def setup_llm(self):
        """
        –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å.
        """
        logger.info("\nü§ñ –®–∞–≥ 5: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏")

        self.llm = RecipeLLM("Qwen/Qwen2.5-1.5B-Instruct")

        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
        model_info = self.llm.get_model_info()
        logger.info(f"üìã –ú–æ–¥–µ–ª—å: {model_info.get('model_name', 'unknown')}")
        logger.info(f"üìã –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: ~{model_info.get('num_parameters', 0):,}")
        logger.info("‚úÖ LLM –≥–æ—Ç–æ–≤–∞")

    def _initialize_full_pipeline_sync(self, max_recipes: int = None, force_rebuild: bool = False):
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–ª–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.
        """
        logger.info("üöÄ –ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG –ø–∞–π–ø–ª–∞–π–Ω–∞")

        start_time = time.time()

        # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.setup_embeddings()
        self.load_and_process_data(max_recipes)
        self.build_vector_index(force_rebuild)
        self.setup_hybrid_search()
        self.setup_reranker()  # –ù–æ–≤—ã–π —à–∞–≥
        self.setup_llm()

        elapsed = time.time() - start_time
        logger.info(f"\n‚úÖ –ü–æ–ª–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed:.1f}—Å")
        logger.info("üéâ RAG –ø–∞–π–ø–ª–∞–π–Ω –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")

    def initialize_full_pipeline(self, max_recipes: int = None, force_rebuild: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø–∞–π–ø–ª–∞–π–Ω –∑–∞ –æ–¥–∏–Ω –≤—ã–∑–æ–≤.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.

        Args:
            max_recipes: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤
            force_rebuild: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ running event loop
            loop = asyncio.get_running_loop()
            # –ï—Å–ª–∏ –µ—Å—Ç—å loop, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ executor
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._initialize_full_pipeline_sync, max_recipes, force_rebuild)
                return future.result()
        except RuntimeError:
            # –ù–µ—Ç event loop - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return self._initialize_full_pipeline_sync(max_recipes, force_rebuild)

    def _search_recipes_sync(self, query: str, k: int = 5) -> List[tuple]:
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ä–µ—Ü–µ–ø—Ç–æ–≤ —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º.
        """
        if not self.hybrid_search or not self.embedder:
            raise ValueError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
        query_embedding = self.embedder.encode_query(query)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º k –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
        initial_k = min(k * 3, 20)  # –ë–µ—Ä–µ–º –±–æ–ª—å—à–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –¥–ª—è —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–∞
        raw_results = self.hybrid_search.hybrid_search(
            query=query,
            query_embedding=query_embedding,
            k=initial_k,
            alpha=0.6,
        )

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if self.reranker and raw_results:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            docs = [doc for doc, _ in raw_results]

            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—é
            filter_result = self.reranker.filter_by_intent(query, docs)
            filtered_docs = filter_result['filtered_docs']
            intent_info = filter_result['intent_info']

            logger.info(f"üéØ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ: {intent_info['intent']} (confidence: {intent_info['confidence']:.2f})")

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥
            if filtered_docs:
                reranked_docs = self.reranker.rerank(query, filtered_docs, top_k=k)
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ (doc, score)
                return [(doc, i) for i, doc in enumerate(reranked_docs)]
            else:
                logger.warning("‚ö†Ô∏è –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—é –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        return raw_results[:k]

    def search_recipes(self, query: str, k: int = 5) -> List[tuple]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ —Ä–µ—Ü–µ–ø—Ç–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ running event loop
            loop = asyncio.get_running_loop()
            # –ï—Å–ª–∏ –µ—Å—Ç—å loop, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ executor
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._search_recipes_sync, query, k)
                return future.result()
        except RuntimeError:
            # –ù–µ—Ç event loop - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return self._search_recipes_sync(query, k)

    def _ask_sync(self, question: str) -> Dict[str, Any]:
        """
        –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å.
        """
        if not all([self.hybrid_search, self.embedder, self.llm]):
            raise ValueError("–ü–∞–π–ø–ª–∞–π–Ω –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        logger.info(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")

        start_time = time.time()

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ—Ü–µ–ø—Ç–æ–≤ —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º
        search_results = self._search_recipes_sync(question, k=5)

        search_time = time.time() - start_time

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        response = self.llm.generate_response(question, search_results)

        total_time = time.time() - start_time

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "question": question,
            "answer": response,
            "found_recipes": len(search_results) if search_results is not None else 0,
            "search_results": [
                {
                    "name": doc.get("name", ""),
                    "ingredients": doc.get("ingredients_text", ""),
                    "url": doc.get("url", ""),
                    "relevance_score": float(score) if isinstance(score, (int, float)) else 0.0,
                }
                for doc, score in (search_results or [])[:3]
            ],
            "timing": {"search_time": round(search_time, 3), "total_time": round(total_time, 3)},
        }

        logger.info(f"üí¨ –û—Ç–≤–µ—Ç: {response}")
        logger.info(f"‚è±Ô∏è –í—Ä–µ–º—è: {total_time:.3f}—Å (–ø–æ–∏—Å–∫: {search_time:.3f}—Å)")

        return result

    def ask(self, question: str) -> Dict[str, Any]:
        """
        –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ —Ä–µ—Ü–µ–ø—Ç–∞—Ö.
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç sync/async –∫–æ–Ω—Ç–µ–∫—Å—Ç.
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ running event loop
            loop = asyncio.get_running_loop()
            # –ï—Å–ª–∏ –µ—Å—Ç—å loop, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤ executor
            with concurrent.futures.ThreadPoolExecutor() as executor:
                future = executor.submit(self._ask_sync, question)
                return future.result()
        except RuntimeError:
            # –ù–µ—Ç event loop - —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
            return self._ask_sync(question)
